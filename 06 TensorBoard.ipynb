{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757497e3-bf2d-41af-b68c-926265171339",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "\n",
    "TensorBoard is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by your model, visualize complex multidimensional data projected down to 3D and automatically clustered for you, and more! This tool is installed automatically when\n",
    "you install TensorFlow, so you already have it!\n",
    "\n",
    "To use it, you must modify your program so that it outputs the data you want to visualize to special binary log files called event files. Each binary data record is called a summary. The TensorBoard server will monitor the log directory, and it will automatically pick up the changes and update the visualizations: this allows you to visualize\n",
    "live data (with a short delay), such as the learning curves during training. In general, you want to point the TensorBoard server to a root log directory, and configure your program so that it writes to a different subdirectory every time it runs. This way, the same TensorBoard server instance will allow you to visualize and compare data from multiple runs of your program, without getting everything mixed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc447361-4c55-4001-beae-31b130283127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f721d975-dc34-4753-9770-60702cf6cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774c8596-5bba-494c-84a8-b92092dc0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52528268-17af-4798-820c-bda825d9a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39b45ec-16b8-4fee-be6d-0776dca24c08",
   "metadata": {},
   "source": [
    "To start with let's define the root log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b0a6ce-ddc1-4920-af33-d5600289b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74fa10-d992-4dd8-995c-373e05416d14",
   "metadata": {},
   "source": [
    "Next we will define a small function that will generate a subdirectory path based on the current date and time, so that it is different at every run. You may want to include extra information in the log directory name, such as hyperparameter values that you are testing, to\n",
    "make it easier to know what you are looking at in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3285704e-7a36-483c-aafa-46a3b5194032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2022_09_27-21_36_09'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "474e4d59-47fc-4342-980c-a3b19830592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 21:36:35.190188: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-27 21:36:35.192071: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44cb718-d9ec-4e4e-90ae-af801a304eff",
   "metadata": {},
   "source": [
    "TensorBoard is a callback, which can be passed as any other callback while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73892348-b29b-467b-a1d1-c80924e278ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86f3759-a43e-49f7-9b71-066549f35fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58085257]\n",
      " [1.9019513 ]\n",
      " [3.607911  ]] [0.477   0.458   5.00001]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_pred, y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a4f4a2-3e9d-4f53-95c3-a5e9e268e965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f6d1ea915e43a528\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f6d1ea915e43a528\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2683e42-9f6a-48f4-aac9-0623f5280e5d",
   "metadata": {},
   "source": [
    "Alternatively, go to this notebook's directory, then type:\n",
    "\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "You can then open your web browser to localhost:6006 and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28909d23-fc8a-4d03-b942-88180b4f084a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2022_09_27-21_51_17'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8658e091-0ef4-4aa7-b4be-01b757257326",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a71708-a4bc-4cbe-adf4-0ce1cb9a735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e52b1261-2a52-4873-829e-8ab558f16329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4493 - val_loss: 17.9525\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 12.4573 - val_loss: 2.4107\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.9406 - val_loss: 0.4016\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4264 - val_loss: 0.4303\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4283 - val_loss: 0.3740\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4150 - val_loss: 0.3954\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4006 - val_loss: 0.3349\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3799 - val_loss: 0.3576\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3711 - val_loss: 0.3323\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3779 - val_loss: 0.3742\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3723 - val_loss: 0.3374\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3553 - val_loss: 0.3447\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3487 - val_loss: 0.3165\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3496 - val_loss: 0.3169\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3476 - val_loss: 0.3141\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3461 - val_loss: 0.3110\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3401 - val_loss: 0.3622\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3391 - val_loss: 0.3049\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3357 - val_loss: 0.3149\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3356 - val_loss: 0.3276\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3360 - val_loss: 0.3446\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3433 - val_loss: 0.3491\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3384 - val_loss: 0.3382\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3338 - val_loss: 0.3202\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3301 - val_loss: 0.2998\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.3292 - val_loss: 0.3029\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3278 - val_loss: 0.2973\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3246 - val_loss: 0.3011\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4171 - val_loss: 0.4385\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5417 - val_loss: 0.5500\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbacdc38-430a-402f-9de9-ef20c84adcfc",
   "metadata": {},
   "source": [
    "Note you can see both the iteration by refreshing the TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0627d-803a-493c-a9d9-e006143c8c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
