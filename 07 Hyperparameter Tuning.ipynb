{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca17939-3e3f-4ca3-a6cf-1db708172cad",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "The flexibility of neural networks is also one of their main drawbacks: there are many hyperparameters to tweak. Not only can you use any imaginable network architecture, but even in a simple MLP you can change the number of layers, the number of neurons per layer, the type of activation function to use in each layer, the weight initialization logic, and much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38c8299-41ae-4fc0-a074-996f2c337cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ef666-5a76-4224-808e-3c0a45b8003f",
   "metadata": {},
   "source": [
    "# GridSearchCV or RandomizedSearchCV \n",
    "\n",
    "- Simply try as many options as possible and see which one works best on Validation set (or use K-cross validation)\n",
    "\n",
    "- For this, we need to wrap our Keras models in objects that mimic regular Scikit-Learn regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21be24cf-28bf-467b-a08d-35a0327f8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c047a911-9073-4326-a524-447c74f0c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51b05c-778e-4cd1-937f-aac4030eaf4d",
   "metadata": {},
   "source": [
    "The options dict is used to ensure that the first layer is properly given the input shape (note that if n_hidden=0, the first layer will be the output layer). It is good practice to provide reasonable defaults to as many hyperparameters as you can, as Scikit-Learn does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a064b1-887e-4238-a4c2-c54f4d90d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = { \"input_shape\": input_shape }\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0493a64-a938-4ae7-b49f-0c6723ac1e65",
   "metadata": {},
   "source": [
    "Next, letâ€™s create a KerasRegressor based on this build_model() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495db89a-2078-4aad-9d5a-db9ac0da2eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravi/anaconda3/envs/keras/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed4e97-d37b-4112-9cff-082c95eb8e8c",
   "metadata": {},
   "source": [
    "Now we can use this object like a regular Scikit-Learn regressor: we can train it using its fit() method, then evaluate it using its score() method, and use it to make predictions using its predict() method. Note that any extra parameter you pass to the fit() method will simply get passed to the underlying Keras model. Also note that the score will be the opposite of the MSE because Scikit-Learn wants scores, not losses (i.e., higher should be better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537c374a-971f-45a2-9718-53cebc41a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.0896 - val_loss: 20.7721\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7606 - val_loss: 5.0266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.5456 - val_loss: 0.5490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4732 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4503 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4338 - val_loss: 0.4129\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4241 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4168 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4108 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4060 - val_loss: 0.4071\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.4021 - val_loss: 0.3855\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3984 - val_loss: 0.4136\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3951 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3921 - val_loss: 0.3818\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3894 - val_loss: 0.3829\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3869 - val_loss: 0.3739\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3848 - val_loss: 0.4022\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3829 - val_loss: 0.3873\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3807 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3791 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3774 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3756 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3742 - val_loss: 0.3523\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3725 - val_loss: 0.3842\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3710 - val_loss: 0.4162\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3700 - val_loss: 0.3980\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3691 - val_loss: 0.3474\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3677 - val_loss: 0.3920\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3670 - val_loss: 0.3566\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3653 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3647 - val_loss: 0.3721\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3633 - val_loss: 0.3948\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3632 - val_loss: 0.3423\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3617 - val_loss: 0.3453\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3610 - val_loss: 0.4068\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3608 - val_loss: 0.3417\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3596 - val_loss: 0.3787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3589 - val_loss: 0.3379\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3582 - val_loss: 0.3419\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3572 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3570 - val_loss: 0.3659\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3563 - val_loss: 0.3803\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3552 - val_loss: 0.3765\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3548 - val_loss: 0.3813\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3543 - val_loss: 0.3326\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3532 - val_loss: 0.3385\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3527 - val_loss: 0.3655\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3521 - val_loss: 0.3579\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3525 - val_loss: 0.3360\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3510 - val_loss: 0.3317\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3504 - val_loss: 0.3562\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3502 - val_loss: 0.3521\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3496 - val_loss: 0.4580\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3497 - val_loss: 0.3809\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3490 - val_loss: 0.3540\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3485 - val_loss: 0.3725\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3478 - val_loss: 0.3337\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3469 - val_loss: 0.4011\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3476 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3466 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3453 - val_loss: 0.3349\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3453 - val_loss: 0.3541\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3445 - val_loss: 0.3428\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3451 - val_loss: 0.3281\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3437 - val_loss: 0.3292\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3431 - val_loss: 0.3301\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3428 - val_loss: 0.3254\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3423 - val_loss: 0.3245\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3419 - val_loss: 0.3255\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3413 - val_loss: 0.3668\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3414 - val_loss: 0.3369\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3405 - val_loss: 0.3267\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3400 - val_loss: 0.3245\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3402 - val_loss: 0.3665\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3397 - val_loss: 0.3290\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3395 - val_loss: 0.3235\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3383 - val_loss: 0.3387\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3384 - val_loss: 0.3362\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3384 - val_loss: 0.3222\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3376 - val_loss: 0.3631\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3384 - val_loss: 0.3411\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3371 - val_loss: 0.3245\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3368 - val_loss: 0.3269\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3362 - val_loss: 0.4066\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3373 - val_loss: 0.3460\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3360 - val_loss: 0.3190\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3356 - val_loss: 0.3259\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3351 - val_loss: 0.3329\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3349 - val_loss: 0.3221\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3344 - val_loss: 0.3320\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3342 - val_loss: 0.3195\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3338 - val_loss: 0.3409\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3337 - val_loss: 0.3179\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3334 - val_loss: 0.3456\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3329 - val_loss: 0.4674\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3340 - val_loss: 0.3447\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3325 - val_loss: 0.4131\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3330 - val_loss: 0.4786\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3324 - val_loss: 0.3913\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3319 - val_loss: 0.3263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b01513ed0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data = (X_valid, y_valid),\n",
    "              callbacks = [keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf412111-d4ee-4c51-891d-aa35ed09b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3342\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8263d98-18c8-4c02-85df-0b5878240931",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe0e9f1-1f87-47e3-b6a7-a56c5bdb3d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6034199, 1.5396053, 4.1040044], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27323863-f22c-4bd3-8b5c-1a7a23bcdfae",
   "metadata": {},
   "source": [
    "However, we do not actually want to train and evaluate a single model like this, we want to train hundreds of variants and see which one performs best on the validation set. Since there are many hyperparameters, it is preferable to use a randomized search rather than grid search.\n",
    "\n",
    "Note that RandomizedSearchCV uses K-fold cross-validation, so it does not use X_valid and y_valid . These are just used for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99dcbd99-6dd4-4ef7-a721-97bb49e53d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 3.9437 - val_loss: 3.9967\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 2.0232 - val_loss: 4.7805\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.3816 - val_loss: 4.5111\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 1.1342 - val_loss: 3.5513\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.9782 - val_loss: 2.4922\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.8666 - val_loss: 1.9684\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.7865 - val_loss: 1.5219\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7309 - val_loss: 1.2091\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6921 - val_loss: 0.9661\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6627 - val_loss: 0.7840\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6403 - val_loss: 0.6908\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6224 - val_loss: 0.6184\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.6074 - val_loss: 0.5781\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5943 - val_loss: 0.5598\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5827 - val_loss: 0.5392\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5723 - val_loss: 0.5263\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5627 - val_loss: 0.5155\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5537 - val_loss: 0.5054\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5451 - val_loss: 0.4981\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5373 - val_loss: 0.4919\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5298 - val_loss: 0.4858\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5223 - val_loss: 0.4815\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5153 - val_loss: 0.4763\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5083 - val_loss: 0.4733\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5021 - val_loss: 0.4668\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4958 - val_loss: 0.4619\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4900 - val_loss: 0.4575\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4843 - val_loss: 0.4525\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4790 - val_loss: 0.4476\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4741 - val_loss: 0.4436\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4694 - val_loss: 0.4399\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4650 - val_loss: 0.4344\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4608 - val_loss: 0.4308\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4567 - val_loss: 0.4270\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4529 - val_loss: 0.4228\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4492 - val_loss: 0.4200\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4459 - val_loss: 0.4149\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4428 - val_loss: 0.4120\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4397 - val_loss: 0.4084\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4369 - val_loss: 0.4050\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.4341 - val_loss: 0.4021\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4316 - val_loss: 0.3992\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4293 - val_loss: 0.3972\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.4269 - val_loss: 0.3941\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4248 - val_loss: 0.3922\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4227 - val_loss: 0.3906\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4208 - val_loss: 0.3880\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4188 - val_loss: 0.3868\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4171 - val_loss: 0.3844\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4153 - val_loss: 0.3827\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4136 - val_loss: 0.3816\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4121 - val_loss: 0.3795\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4106 - val_loss: 0.3781\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4090 - val_loss: 0.3769\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4075 - val_loss: 0.3755\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4063 - val_loss: 0.3742\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4049 - val_loss: 0.3731\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4035 - val_loss: 0.3721\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4023 - val_loss: 0.3709\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4010 - val_loss: 0.3700\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4000 - val_loss: 0.3690\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3988 - val_loss: 0.3685\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3976 - val_loss: 0.3672\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3967 - val_loss: 0.3665\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3955 - val_loss: 0.3663\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3947 - val_loss: 0.3653\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3936 - val_loss: 0.3642\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3926 - val_loss: 0.3642\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3917 - val_loss: 0.3631\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3907 - val_loss: 0.3624\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3899 - val_loss: 0.3622\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3890 - val_loss: 0.3616\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3882 - val_loss: 0.3609\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3874 - val_loss: 0.3608\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3867 - val_loss: 0.3607\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3858 - val_loss: 0.3602\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3852 - val_loss: 0.3600\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3843 - val_loss: 0.3601\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3836 - val_loss: 0.3590\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3828 - val_loss: 0.3579\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3823 - val_loss: 0.3590\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3815 - val_loss: 0.3605\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3810 - val_loss: 0.3590\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3803 - val_loss: 0.3595\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3796 - val_loss: 0.3577\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3787 - val_loss: 0.3612\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3786 - val_loss: 0.3582\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3779 - val_loss: 0.3575\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3773 - val_loss: 0.3568\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 3s 13ms/step - loss: 0.3767 - val_loss: 0.3580\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3762 - val_loss: 0.3568\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3757 - val_loss: 0.3560\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3751 - val_loss: 0.3555\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3746 - val_loss: 0.3541\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3741 - val_loss: 0.3552\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3733 - val_loss: 0.3560\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3730 - val_loss: 0.3531\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3724 - val_loss: 0.3521\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3718 - val_loss: 0.3573\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3716 - val_loss: 0.3536\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.3946\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 3.4559 - val_loss: 10.1742\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 1.7814 - val_loss: 12.3752\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 1.3318 - val_loss: 11.1189\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 1.0928 - val_loss: 9.5005\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.9378 - val_loss: 7.7134\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8295 - val_loss: 6.3868\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.7528 - val_loss: 5.3099\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6991 - val_loss: 4.2713\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6615 - val_loss: 3.5159\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6345 - val_loss: 2.8677\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.6141 - val_loss: 2.3813\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.5985 - val_loss: 1.8774\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5858 - val_loss: 1.5289\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5750 - val_loss: 1.3169\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5654 - val_loss: 1.0802\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5567 - val_loss: 0.9220\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5489 - val_loss: 0.7778\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.5418 - val_loss: 0.6804\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.5351 - val_loss: 0.5921\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5292 - val_loss: 0.5422\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.5233 - val_loss: 0.5074\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.5179 - val_loss: 0.4961\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5128 - val_loss: 0.4914\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5081 - val_loss: 0.4936\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.5036 - val_loss: 0.5019\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4994 - val_loss: 0.5124\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4952 - val_loss: 0.5176\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4913 - val_loss: 0.5262\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4873 - val_loss: 0.5233\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4843 - val_loss: 0.5384\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4807 - val_loss: 0.5497\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4775 - val_loss: 0.5526\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4744 - val_loss: 0.5561\n",
      "121/121 [==============================] - 1s 7ms/step - loss: 0.4836\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 2.5050 - val_loss: 4.7120\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 1.1298 - val_loss: 3.3634\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.8857 - val_loss: 2.1251\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.7972 - val_loss: 1.5183\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7497 - val_loss: 1.1943\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7169 - val_loss: 0.9902\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6907 - val_loss: 0.8802\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6695 - val_loss: 0.7988\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6511 - val_loss: 0.7529\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6350 - val_loss: 0.7111\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6204 - val_loss: 0.6770\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6070 - val_loss: 0.6475\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5949 - val_loss: 0.6254\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5835 - val_loss: 0.6078\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5732 - val_loss: 0.5907\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5636 - val_loss: 0.5741\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.5548 - val_loss: 0.5602\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5464 - val_loss: 0.5476\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5388 - val_loss: 0.5372\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5315 - val_loss: 0.5282\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5244 - val_loss: 0.5201\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5180 - val_loss: 0.5125\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5119 - val_loss: 0.5055\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5059 - val_loss: 0.5015\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5005 - val_loss: 0.4943\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4953 - val_loss: 0.4895\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4904 - val_loss: 0.4840\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4857 - val_loss: 0.4798\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4812 - val_loss: 0.4785\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4772 - val_loss: 0.4713\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4734 - val_loss: 0.4682\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4697 - val_loss: 0.4665\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4661 - val_loss: 0.4622\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4627 - val_loss: 0.4626\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4596 - val_loss: 0.4593\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4565 - val_loss: 0.4572\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4536 - val_loss: 0.4555\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4508 - val_loss: 0.4533\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4481 - val_loss: 0.4527\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4456 - val_loss: 0.4506\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4430 - val_loss: 0.4531\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4409 - val_loss: 0.4518\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4387 - val_loss: 0.4489\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4366 - val_loss: 0.4493\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4345 - val_loss: 0.4489\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4326 - val_loss: 0.4467\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4307 - val_loss: 0.4473\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4289 - val_loss: 0.4479\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4271 - val_loss: 0.4484\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4255 - val_loss: 0.4483\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4237 - val_loss: 0.4471\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4223 - val_loss: 0.4481\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4207 - val_loss: 0.4483\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4193 - val_loss: 0.4487\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4177 - val_loss: 0.4515\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4164 - val_loss: 0.4505\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.4171\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6250 - val_loss: 29.0191\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7709 - val_loss: 38.5820\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0974 - val_loss: 115.8328\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1960 - val_loss: 200.3343\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4083 - val_loss: 557.7498\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 8.4129 - val_loss: 1328.7948\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 15.0315 - val_loss: 3037.8542\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 44.2108 - val_loss: 7033.7915\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 81.2460 - val_loss: 16695.9766\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 268.7122 - val_loss: 40306.6602\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 481.5962 - val_loss: 91736.2031\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 247.6956\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1167 - val_loss: 0.7265\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6738 - val_loss: 5.0576\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 11.5317\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5621 - val_loss: 15.7839\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5413 - val_loss: 18.3588\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5280 - val_loss: 19.8297\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5194 - val_loss: 20.2813\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5134 - val_loss: 20.9396\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5089 - val_loss: 20.7335\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5067 - val_loss: 19.0589\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5054 - val_loss: 19.9564\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.9765\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6247 - val_loss: 42.1100\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8160 - val_loss: 43.8643\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9823 - val_loss: 108.8697\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2650 - val_loss: 181.6127\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4925 - val_loss: 399.2610\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5464 - val_loss: 506.0509\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3693 - val_loss: 771.3759\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 11.6119 - val_loss: 1192.3922\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 12.5820 - val_loss: 1745.3912\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7.6187 - val_loss: 2182.7808\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 42.2748 - val_loss: 3018.2271\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 4.6615\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 1.0472 - val_loss: 17.7488\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.9496 - val_loss: 52.6411\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8558 - val_loss: 67.4902\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5061 - val_loss: 1.3470\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4209 - val_loss: 0.3740\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3927 - val_loss: 0.4150\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3810 - val_loss: 0.3903\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3739 - val_loss: 0.4028\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3685 - val_loss: 0.4020\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3653 - val_loss: 0.3926\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3628 - val_loss: 0.4067\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3590 - val_loss: 0.3614\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3554 - val_loss: 0.3790\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3543 - val_loss: 0.3886\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3518 - val_loss: 0.3722\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3510 - val_loss: 0.3753\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3480 - val_loss: 0.3753\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3470 - val_loss: 0.3770\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3453 - val_loss: 0.3720\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3436 - val_loss: 0.3707\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3435 - val_loss: 0.3748\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3424 - val_loss: 0.3663\n",
      "121/121 [==============================] - 1s 7ms/step - loss: 0.3620\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.9013 - val_loss: 0.7625\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4906 - val_loss: 0.7752\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4457 - val_loss: 0.4346\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4273 - val_loss: 0.3983\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4146 - val_loss: 0.4344\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4059 - val_loss: 0.5871\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4025 - val_loss: 0.8936\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3958 - val_loss: 0.8674\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3919 - val_loss: 1.0651\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3908 - val_loss: 0.8333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3860 - val_loss: 1.0883\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3818 - val_loss: 0.9756\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3814 - val_loss: 1.0974\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3805 - val_loss: 1.0437\n",
      "121/121 [==============================] - 1s 6ms/step - loss: 0.4079\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.9156 - val_loss: 4.8268\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.5270 - val_loss: 8.5456\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4712 - val_loss: 25.3096\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 1.0254 - val_loss: 6.7016\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4560 - val_loss: 17.3660\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5717 - val_loss: 28.9780\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5830 - val_loss: 0.3823\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4114 - val_loss: 0.3699\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4011 - val_loss: 0.3630\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3961 - val_loss: 0.3575\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3914 - val_loss: 0.3563\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3859 - val_loss: 0.3557\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3817 - val_loss: 0.3522\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3785 - val_loss: 0.3513\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3757 - val_loss: 0.3479\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3728 - val_loss: 0.3450\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3691 - val_loss: 0.3483\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3717 - val_loss: 0.3489\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3656 - val_loss: 0.3448\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3631 - val_loss: 0.3457\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3638 - val_loss: 0.3437\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.3609 - val_loss: 0.3473\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3582 - val_loss: 0.3481\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3568 - val_loss: 0.3482\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3561 - val_loss: 0.3474\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3550 - val_loss: 0.3515\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3523 - val_loss: 0.3481\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3528 - val_loss: 0.3510\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3649 - val_loss: 0.3532\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3506 - val_loss: 0.3535\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3496 - val_loss: 0.3546\n",
      "121/121 [==============================] - 1s 7ms/step - loss: 0.3423\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.9150 - val_loss: 16.8511\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7458 - val_loss: 11.2617\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.6682 - val_loss: 5.0033\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4351 - val_loss: 0.3819\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4053 - val_loss: 0.3770\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3944 - val_loss: 0.3924\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3892 - val_loss: 0.3983\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3834 - val_loss: 0.4021\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.3788 - val_loss: 0.4046\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3755 - val_loss: 0.4132\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3728 - val_loss: 0.3967\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.3699 - val_loss: 0.4072\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3662 - val_loss: 0.4023\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3636 - val_loss: 0.3914\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3619 - val_loss: 0.3895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f5b0324a990>,\n",
       "                   n_iter=3,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f5aa0d1ebd0>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\" : [0, 1, 2, 3],\n",
    "    \"n_neurons\" : np.arange(1, 100),\n",
    "    \"learning_rate\" : reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=3, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fd8ed-a08c-46df-a388-d9f37cb6addb",
   "metadata": {},
   "source": [
    "access the best parameters found, the best score, and the trained Keras model like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f84e90-8f32-4872-96f0-d267257fabb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.008339092654580042, 'n_hidden': 1, 'n_neurons': 38}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84356434-65f7-466d-9519-17148bd9ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3707270125548045"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150a6c42-eb1d-407a-9ca0-b8fb11801222",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a792aa6-e87a-45db-9825-18c6cf0cf9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35634645819664"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec36c2-8ef5-451f-a88e-edd15968a5f9",
   "metadata": {},
   "source": [
    "You can now save this model, evaluate it on the test set, and if you are satisfied with its performance, deploy it to production. Using randomized search is not too hard, and it works well for many fairly simple problems. However, when training is slow (e.g., for more complex problems with larger datasets), this approach will only explore a tiny portion of the hyperparameter space. You can partially alleviate this\n",
    "problem by assisting the search process manually: first run a quick random search using wide ranges of hyperparameter values, then run another search using smaller ranges of values centered on the best ones found during the first run, and so on. This will hopefully zoom in to a good set of hyperparameters. However, this is very time consuming, and probably not the best use of your time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef1b518-d1a1-4be4-a0ee-b991ca4f8c10",
   "metadata": {},
   "source": [
    "Here are a few Python libraries you can use to optimize hyperparameters:\n",
    "â€¢ Hyperopt: a popular Python library for optimizing over all sorts of complex search spaces (including real values such as the learning rate, or discrete values such as the number of layers).\n",
    "â€¢ Hyperas, kopt or Talos: optimizing hyperparameters for Keras model (the first two are based on Hyperopt).\n",
    "â€¢ Scikit-Optimize (skopt): a general-purpose optimization library. The Bayes SearchCV class performs Bayesian optimization using an interface similar to Grid SearchCV .\n",
    "â€¢ Spearmint: a Bayesian optimization library.\n",
    "â€¢ Sklearn-Deap: a hyperparameter optimization library based on evolutionary algorithms, also with a GridSearchCV -like interface.\n",
    "â€¢ And many more!\n",
    "Moreover, many companies offer services for hyperparameter optimization. For example Google Cloud ML Engine has a hyperparameter tuning service. Other companies provide APIs for hyperparameter optimization, such as Arimo, SigOpt, Oscar and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb48a84-aeb2-47fb-a993-7b25d8d17247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
